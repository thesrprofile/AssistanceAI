# **Assistance AI - Project Overview**  

ğŸš€ **Assistance AI** is a **chatbot application** powered by **Hugging Faceâ€™s open-source LLM (Mistral-7B)** and deployed using **Flask & Render**. It provides **real-time AI-powered responses** in a simple, user-friendly web interface.  

---

## **ğŸ“Œ Key Features**  
âœ… **Open-Source AI Model** â€“ Uses `mistralai/Mistral-7B-Instruct-v0.1` from Hugging Face.  
âœ… **Real-Time Chat Interface** â€“ Send messages and get AI-generated responses instantly.  
âœ… **Simple & Scalable Backend** â€“ Built with **Flask** (Python) for easy modifications.  
âœ… **Secure API Handling** â€“ Uses `.env` to protect Hugging Face API keys.  
âœ… **Production-Ready Deployment** â€“ Hosted on **Render** with Gunicorn for reliability.  

---

## **ğŸ› ï¸ Tech Stack**  
| Category       | Technology Used |
|---------------|----------------|
| **Backend**   | Flask (Python) |
| **Frontend**  | HTML, CSS, JS |
| **AI Model**  | Hugging Face API (Mistral-7B) |
| **Deployment** | Render (Gunicorn) |
| **Security**  | `.env` for API keys |

---

## **ğŸ“‚ Project Structure**  
```
assistance-ai/
â”œâ”€â”€ app.py              # Flask backend (handles API calls)
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ .env                # Stores Hugging Face API key
â””â”€â”€ templates/
    â””â”€â”€ chat.html       # Frontend chat interface
```

---

## **ğŸ”§ How It Works**  
1. **User Input** â†’ Message sent via frontend (HTML/JS).  
2. **Flask Backend** â†’ Processes request & queries Hugging Face API.  
3. **AI Response** â†’ Mistral-7B generates a reply.  
4. **Output** â†’ Response displayed in the chatbox.  

---

## **ğŸš€ Deployment**  
Hosted on **Render** using:  
- **Gunicorn** (Production WSGI Server)  
- **Hugging Face Inference API** (Free Tier)  

ğŸ”— **Live Demo:** https://assistanceai.onrender.com/  

---

## **âš™ï¸ Setup & Run Locally**  

### **1. Clone the Repository**  
```bash
git clone https://github.com/yourusername/assistance-ai.git
cd assistance-ai
```

### **2. Install Dependencies**  
```bash
pip install -r requirements.txt
```

### **3. Add Hugging Face API Key**  
Create `.env` file:  
```env
HF_API_KEY="your_huggingface_api_token"
```

### **4. Run Flask App**  
```bash
python app.py
```
Visit â†’ `http://localhost:5000`  

### **5. Deploy to Render**  
- Push to GitHub & connect to Render.  
- Set **Start Command:** `gunicorn app:app`  

---

## **ğŸ“œ Future Improvements**  
ğŸ”¹ **Add More Models** (e.g., Llama 3, GPT-2)  
ğŸ”¹ **Streaming Responses** (Better UX)  
ğŸ”¹ **User Authentication** (Optional)  
ğŸ”¹ **Mobile App Integration** (Flutter/React Native)  

---

## **ğŸ™ Credits**  
- **Hugging Face** for the open-source LLM API.  
- **Render** for free cloud hosting.  
- **Flask & Gunicorn** for backend stability.  

---

## **ğŸ“„ License**  
MIT License - Free for personal & commercial use.  

---
